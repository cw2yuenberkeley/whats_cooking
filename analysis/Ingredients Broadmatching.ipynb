{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from numpy import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in ingredients\n",
    "ing_df = pd.read_csv(\"ingredients.csv\").set_index('ingredient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_ingredient(s):\n",
    "    lm = WordNetLemmatizer()\n",
    "    printable = string.printable\n",
    "    PERMITTED_CHARS = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ \" \n",
    "\n",
    "    filter(lambda x: x in printable, s)\n",
    "    s = \"\".join(c for c in s if c in PERMITTED_CHARS)\n",
    "    s = lm.lemmatize(s.lower())\n",
    "\n",
    "    return s    \n",
    "\n",
    "# Given an ingredient, return all subsets of the ingredient string as a list of strings\n",
    "def get_substrings(ingredient):\n",
    "    # Base case - Return an empty list of the string is empty\n",
    "    if ingredient == '':\n",
    "        return []\n",
    "    \n",
    "    word_list = ingredient.split(' ')\n",
    "    substring_list = []\n",
    "    substring_list.append(ingredient)\n",
    "    \n",
    "    # Base case - Return a list with only the ingredient if there is only one word\n",
    "    if len(word_list) == 1:\n",
    "        return substring_list\n",
    "    \n",
    "    # Recursive Case\n",
    "    for i in range(len(word_list)):\n",
    "        new_list = np.array(word_list, copy=True).tolist()\n",
    "        new_list.remove(word_list[i])\n",
    "        substring_word = ' '.join(new_list)\n",
    "        substring_list.append(substring_word)\n",
    "        \n",
    "        sub_list = get_substrings(substring_word)\n",
    "        for w in sub_list:\n",
    "            substring_list.append(w)\n",
    "\n",
    "    return substring_list\n",
    "\n",
    "# Dedupes the output list of get_substrings function\n",
    "def get_substrings_deduped(substring_list):\n",
    "    return np.unique(get_substrings(substring_list)).tolist()\n",
    "\n",
    "def broadmatch(ing):\n",
    "    if len(ing.split(' ')) > 10:\n",
    "        return ing\n",
    "    \n",
    "    df = pd.DataFrame(get_substrings_deduped(ing), columns=['ingredient']).set_index('ingredient')\n",
    "    joined_df = df.join(ing_df, lsuffix = 'l', rsuffix='r')\n",
    "    normalized_ingredient = joined_df['num_recipes'].idxmax()\n",
    "    return normalized_ingredient if not type(normalized_ingredient) == float else ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_ing_arr = []\n",
    "for i in range(len(ing_df.index)):\n",
    "    norm_ing_arr.append([format_ingredient(ing_df.index[i]), broadmatch(format_ingredient(ing_df.index[i]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_ing_df = pd.DataFrame(norm_ing_arr, columns = ['Original Ingredient', 'Broadmatched Ingredient'])\n",
    "norm_ing_df.head()\n",
    "\n",
    "norm_ing_df.to_csv(\"broadmatched_ingredients.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
